{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afde9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "filepath = \"../../datasets/ml-20m\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e3c47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000263, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(filepath, \"ratings.csv\"))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc940100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1        2     3.5  1112486027\n",
      "1       1       29     3.5  1112484676\n",
      "2       1       32     3.5  1112484819\n",
      "3       1       47     3.5  1112484727\n",
      "4       1       50     3.5  1112484580\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5191be21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  click   timestamp\n",
      "0       1        2      0  1112486027\n",
      "1       1       29      0  1112484676\n",
      "2       1       32      0  1112484819\n",
      "3       1       47      0  1112484727\n",
      "4       1       50      0  1112484580\n"
     ]
    }
   ],
   "source": [
    "# binarize the explicit data by keeping ratings of four or higher and interpret them as implicit feedback\n",
    "df['rating'] = df['rating'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "df.rename(columns={'rating': 'click'}, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6908f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000263, 4)\n"
     ]
    }
   ],
   "source": [
    "# We only keep users who have watched at least 5 movies\n",
    "df = df.groupby('userId').filter(lambda x: len(x) >= 5)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d5649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19984024, 4)\n"
     ]
    }
   ],
   "source": [
    "# We only keep movies with at least 5 interactions\n",
    "df = df.groupby('movieId').filter(lambda x: len(x) >= 5)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf57aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540654085\n"
     ]
    }
   ],
   "source": [
    "# Create a user-movie interaction matrix, oh wait, this is a huuuge table!!!!!\n",
    "# user_movie_matrix = df.pivot_table(index='userId', columns='movieId', values='rating', aggfunc='sum', fill_value=0)\n",
    "# user_movie_matrix.head()\n",
    "\n",
    "# alternative solution, lazy load table when needed, defined in vae.ipynb\n",
    "print(len(df['userId'].unique())*len(df['movieId'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc7c8fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (17065612, 4)\n"
     ]
    }
   ],
   "source": [
    "holdout_size = 20000\n",
    "# randomly select 20000 holdout users, according to the paper\n",
    "holdout_userid = df['userId'].drop_duplicates().sample(n=holdout_size, random_state=42)\n",
    "\n",
    "# Train\n",
    "# Create train data based on all history of non-holdout userid\n",
    "train_df = df[~df['userId'].isin(holdout_userid)]\n",
    "# train_df.to_csv(os.path.join(filepath, \"train.csv\"), index=False)\n",
    "print(\"Train: \", train_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bede0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdout (20000 users)\n",
    "houldout_df = df[df['userId'].isin(holdout_userid)]\n",
    "\n",
    "# split houldout equally between val and test\n",
    "val_userid = houldout_df['userId'].drop_duplicates().sample(n=holdout_size // 2, random_state=42)\n",
    "val_df = houldout_df[houldout_df['userId'].isin(val_userid)]\n",
    "test_df = houldout_df[~houldout_df['userId'].isin(val_userid)]\n",
    "# val_df.to_csv(os.path.join(filepath, \"val.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(filepath, \"test.csv\"), index=False)\n",
    "# print(\"val_df:\", val_df.shape)\n",
    "# print(\"test_df:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "891e94c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def split_train_test_proportion(data, test_prop=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits each user's interactions randomly into a training and a test set\n",
    "    based on the specified proportion (test_prop).\n",
    "    \"\"\"\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    for _, group in data_grouped_by_user:\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        # Only split users with a minimum number of interactions (e.g., 5)\n",
    "        # Note: If you filtered users earlier, this check might be less crucial.\n",
    "        if n_items_u >= 5:\n",
    "            # Create a boolean array to index the test items\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            \n",
    "            # Randomly select indices for the test items\n",
    "            test_indices = np.random.choice(\n",
    "                n_items_u, \n",
    "                size=int(test_prop * n_items_u), \n",
    "                replace=False\n",
    "            ).astype('int64')\n",
    "            \n",
    "            idx[test_indices] = True\n",
    "\n",
    "            # Append 80% to train list, 20% to test list\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            # Keep users with < 5 items entirely in the training set (tr)\n",
    "            tr_list.append(group)\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06e948f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation observation set (val_df_tr) shape: (1171109, 4)\n",
      "Validation held-out set (val_df_te) shape: (287915, 4)\n",
      "Test observation set (test_df_tr) shape: (1171298, 4)\n",
      "Test held-out set (test_df_te) shape: (288090, 4)\n"
     ]
    }
   ],
   "source": [
    "# 1. Split Validation User Interactions (80% for observation, 20% for evaluation)\n",
    "val_df_tr, val_df_te = split_train_test_proportion(val_df, test_prop=0.2)\n",
    "\n",
    "# 2. Split Test User Interactions (80% for observation, 20% for evaluation)\n",
    "test_df_tr, test_df_te = split_train_test_proportion(test_df, test_prop=0.2)\n",
    "\n",
    "# Now, save the new files\n",
    "# The original 'train.csv' (from non-holdout users) will be merged with \n",
    "# val_df_tr and test_df_tr later when building the final training matrix.\n",
    "# For now, save the necessary components:\n",
    "\n",
    "# val_df_tr.to_csv(os.path.join(filepath, \"val_tr.csv\"), index=False)\n",
    "val_df_te.to_csv(os.path.join(filepath, \"val.csv\"), index=False)\n",
    "\n",
    "# test_df_tr.to_csv(os.path.join(filepath, \"test_tr.csv\"), index=False)\n",
    "test_df_te.to_csv(os.path.join(filepath, \"test.csv\"), index=False)\n",
    "\n",
    "print(f\"Validation observation set (val_df_tr) shape: {val_df_tr.shape}\")\n",
    "print(f\"Validation held-out set (val_df_te) shape: {val_df_te.shape}\")\n",
    "print(f\"Test observation set (test_df_tr) shape: {test_df_tr.shape}\")\n",
    "print(f\"Test held-out set (test_df_te) shape: {test_df_te.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6439c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train_df, val_df_tr, test_df_tr], ignore_index=True).to_csv(os.path.join(filepath, \"train.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97838ac2",
   "metadata": {},
   "source": [
    "Official Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d58e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(os.path.join(filepath, 'ratings.csv'), header=0)\n",
    "raw_data = raw_data[raw_data['rating'] > 3.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83eb6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count\n",
    "\n",
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "   # 1. Filter items (min_sc)\n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        # Corrected line: Get the index of 'movieId's where count >= min_sc\n",
    "        valid_items = itemcount[itemcount >= min_sc].index\n",
    "        tp = tp[tp['movieId'].isin(valid_items)]\n",
    "    \n",
    "    # 2. Filter users (min_uc)\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        # Corrected line: Get the index of 'userId's where count >= min_uc\n",
    "        valid_users = usercount[usercount >= min_uc].index\n",
    "        tp = tp[tp['userId'].isin(valid_users)]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb30cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 9980096 watching events from 138081 users and 20688 movies (sparsity: 0.349%)\n"
     ]
    }
   ],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)\n",
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f77c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]\n",
    "\n",
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 10000\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users):]\n",
    "\n",
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]\n",
    "unique_sid = pd.unique(train_plays['movieId'])\n",
    "\n",
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
    "\n",
    "pro_dir = os.path.join(filepath, 'pro_sg')\n",
    "\n",
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "850fdbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te\n",
    "\n",
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b2148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f28700",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b81da666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b25fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])\n",
    "\n",
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train_official.csv'), index=False)\n",
    "\n",
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
    "\n",
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
    "\n",
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
    "\n",
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cb847bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66756</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66756</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66756</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid  sid\n",
       "0  66756    0\n",
       "1  66756    1\n",
       "2  66756    2\n",
       "3  66756    3\n",
       "4  66756    4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b742a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

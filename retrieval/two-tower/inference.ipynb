{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce379eb1",
   "metadata": {},
   "source": [
    "Given User data, generate query embeddings, then search for top k candidate embeddings. With a holdout validation data, we can compare and see if top k results captured the next track the user actually listened (recall@k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e065f249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paataugrekhelidze/Projects/Recsys/retrieval/two-tower/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating samples from sequences...\n",
      "Generated 1352980 total samples.\n"
     ]
    }
   ],
   "source": [
    "import tower\n",
    "from datasets import load_from_disk\n",
    "import os\n",
    "\n",
    "# load validation dataset (already processed for simplicity)\n",
    "filepath = '../../datasets/yambda/processed'\n",
    "val_processed = load_from_disk(os.path.join(filepath, \"val\"))\n",
    "\n",
    "val_dataset = tower.MusicWindowDataset(data = val_processed, \n",
    "                                   n = 10, \n",
    "                                   global_t_max = 0, # does not really matter, will be set to 0 in forward pass\n",
    "                                   max_windows_per_user=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c0d0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load query model\n",
    "from tower import QueryTower\n",
    "import os\n",
    "import torch\n",
    "\n",
    "len_unique_users = 9238\n",
    "len_unique_items = 877168\n",
    "len_unique_albums = 3367691\n",
    "len_unique_artists = 1293394\n",
    "\n",
    "user_embed_size = 14\n",
    "item_embed_size = 20\n",
    "album_embed_size = 22\n",
    "artist_embed_size = 21\n",
    "\n",
    "\n",
    "\n",
    "query_input_size = user_embed_size + 2*item_embed_size + 2*artist_embed_size + 2*album_embed_size + 3\n",
    "candidate_input_size = item_embed_size + artist_embed_size + album_embed_size + 1\n",
    "\n",
    "# initialize embeddings\n",
    "item_embed = torch.nn.Embedding(num_embeddings=len_unique_items+1, embedding_dim=item_embed_size)\n",
    "album_embed = torch.nn.Embedding(num_embeddings=len_unique_albums+1, embedding_dim=album_embed_size)\n",
    "artist_embed = torch.nn.Embedding(num_embeddings=len_unique_artists+1, embedding_dim=artist_embed_size)\n",
    "\n",
    "# initialize and test query tower\n",
    "query_model = QueryTower(input_size = query_input_size,\n",
    "                         hidden_size = [1024, 512, 128],\n",
    "                         user_num_embeddings = len_unique_users+1,\n",
    "                         user_embed_size = user_embed_size,\n",
    "                         item_embed = item_embed,\n",
    "                         artist_embed = artist_embed,\n",
    "                         album_embed = album_embed,\n",
    "                         log_age_mean = 15.874020,\n",
    "                         log_age_std = 1.090574\n",
    "                        )\n",
    "\n",
    "\n",
    "# load last checkpoint, loads saved weights for embeddings as well as the query hidden layers\n",
    "checkpoints = \"./checkpoints\"\n",
    "checkpoint = torch.load(os.path.join(checkpoints, f\"last_checkpoint.pth\"))\n",
    "query_model.load_state_dict(checkpoint[\"query_model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7bdbca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for the Validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [03:08<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = \"mps\"\n",
    "B = 8192\n",
    "query_model.to(device)\n",
    "query_model.eval()\n",
    "\n",
    "query_dataloader = DataLoader(val_dataset, batch_size=B, num_workers=8)\n",
    "all_val_query_embeddings = []\n",
    "all_val_target_ids = []\n",
    "\n",
    "print(\"Generating embeddings for the Validation set...\")\n",
    "with torch.no_grad():\n",
    "    for query, item, _ in tqdm(query_dataloader):\n",
    "        # Move batch to the correct device\n",
    "        batch = {k: v.to(device) for k, v in query.items()}\n",
    "        \n",
    "        # Generate embeddings\n",
    "        query_embeddings = query_model(batch)        \n",
    "        # Normalize embeddings (important for Faiss with inner product)\n",
    "        query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Move to CPU and convert to numpy\n",
    "        all_val_query_embeddings.append(query_embeddings.cpu().numpy())\n",
    "        all_val_target_ids.append(item[\"candidate_id\"].numpy())\n",
    "\n",
    "val_query_embeddings_np = np.concatenate(all_val_query_embeddings, axis=0)\n",
    "val_target_np = np.concatenate(all_val_target_ids, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06406858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1352980, 128) (1352980,)\n"
     ]
    }
   ],
   "source": [
    "print(val_query_embeddings_np.shape, val_target_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d877a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index table\n",
    "\n",
    "import faiss\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d66e5b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@5: 0.012\n",
      "recall@10: 0.01925\n",
      "recall@30: 0.0405\n",
      "recall@50: 0.05225\n",
      "recall@100: 0.07375\n",
      "recall@300: 0.12575\n",
      "recall@500: 0.166\n",
      "recall@1000: 0.229\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(\"baseline.index\") # baseline knn\n",
    "# sample_size = len(val_query_embeddings_np)\n",
    "sample_size = 4000\n",
    "for k in [5, 10, 30, 50, 100, 300, 500, 1000]:\n",
    "    # search top k    \n",
    "    _, I = index.search(val_query_embeddings_np[:sample_size], k)\n",
    "\n",
    "    # unsqueeze target array to (sample, 1) then broadcast comparison\n",
    "    hits = (I == val_target_np[:sample_size][:, None])\n",
    "    recall_k = hits.any(axis=1).mean() # capture any True in a row, then take mean of every row\n",
    "    print(f\"recall@{k}: {recall_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10c711af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@5: 0.005\n",
      "recall@10: 0.00875\n",
      "recall@30: 0.0185\n",
      "recall@50: 0.0235\n",
      "recall@100: 0.03375\n",
      "recall@300: 0.0585\n",
      "recall@500: 0.07725\n",
      "recall@1000: 0.114\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(\"items.index\") # IVFPQ\n",
    "sample_size = 4000\n",
    "for k in [5, 10, 30, 50, 100, 300, 500, 1000]:\n",
    "    # search top k    \n",
    "    _, I = index.search(val_query_embeddings_np[:sample_size], k)\n",
    "\n",
    "    # unsqueeze target array to (sample, 1) then broadcast comparison\n",
    "    hits = (I == val_target_np[:sample_size][:, None])\n",
    "    recall_k = hits.any(axis=1).mean() # capture any True in a row, then take mean of every row\n",
    "    print(f\"recall@{k}: {recall_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e728efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2da582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a8190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "two-tower (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
